{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a category: comp.graphics\n",
      "\n",
      "A random document is selected from the category  comp.graphics  as the source document\n",
      "\n",
      " From: sp1marse@kristin (Marco Seirio)\n",
      "Subject: Flat globe\n",
      "Lines: 13\n",
      "X-Newsreader: Tin 1.1 PL3\n",
      "\n",
      "\n",
      "Does anybody have an algorithm for \"flattening\" out a globe, or any other\n",
      "parametric surface, that is definied parametrically. \n",
      "That is, I would like to take a sheet of paper and a knife and to be\n",
      "able to calculate how I must cut in the paper so I can fold it to a\n",
      "globe (or any other object).\n",
      "\n",
      "\n",
      "      Marco Seirio - In real life sp1marse@caligula.his.se\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The document that is the most similar is presented below : \n",
      "\n",
      "\n",
      " From: koolish@bbn.com (Dick Koolish)\n",
      "Subject: Re: Flat globe\n",
      "Lines: 17\n",
      "NNTP-Posting-Host: bbn.com\n",
      "\n",
      "sp1marse@kristin (Marco Seirio) writes:\n",
      "\n",
      "\n",
      ">Does anybody have an algorithm for \"flattening\" out a globe, or any other\n",
      ">parametric surface, that is definied parametrically. \n",
      ">That is, I would like to take a sheet of paper and a knife and to be\n",
      ">able to calculate how I must cut in the paper so I can fold it to a\n",
      ">globe (or any other object).\n",
      "\n",
      "\n",
      "There is a library of map projections in:\n",
      "\n",
      "    charon.er.usgs.gov\n",
      "\n",
      "in\n",
      "\n",
      "    /pub/PROJ.4.1.3.tar.Z\n",
      "\n",
      "The similarity is :  0.721700196999\n",
      "The category of this document is  comp.graphics\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import random\n",
    "\n",
    "categories = ['alt.atheism','comp.graphics','sci.med','soc.religion.christian']\n",
    "twenty_train = fetch_20newsgroups(subset='train',categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "#user will select a category from which the source document will be selected\n",
    "src_category=input('Enter a category: ')         \n",
    "for (idx,val) in enumerate(twenty_train.target_names):\n",
    "    if (val==src_category):\n",
    "        src_category_index=idx\n",
    "\n",
    "docs_of_src_category=[]          #this list contains the index of all documents of the category user entered\n",
    "for (idx,val) in enumerate(twenty_train.data):        \n",
    "    if(twenty_train.target[idx]==src_category_index):\n",
    "        docs_of_src_category.extend([idx])\n",
    "        \n",
    "random_index=random.randrange(0,len(docs_of_src_category))\n",
    "src_index=docs_of_src_category[random_index]  #src_index is the original index(index in 20 newsgroup dataset) of the randomly selected source document \n",
    "\n",
    "print('\\nA random document is selected from the category ',src_category,' as the source document')\n",
    "print('\\n',twenty_train.data[src_index])\n",
    "#the source document has been displayed\n",
    "\n",
    "\n",
    "#now we are going to find the most similar document to the source document\n",
    "src=twenty_train.data[src_index]\n",
    "max_similar_index=0; max_similarity=0;\n",
    "count_vect = CountVectorizer()\n",
    "tfidf = TfidfTransformer()\n",
    "\n",
    "\n",
    "#Finding out the most similar document to the source document from the 2257 documents of 4 categories from 20 newsgroup data set\n",
    "for(idx,val) in enumerate(twenty_train.data):\n",
    "    target=val\n",
    "    data_set=src,target\n",
    "    term_freq_matrix=count_vect.fit_transform(data_set)\n",
    "    tf_idf_matrix = tfidf.fit_transform(term_freq_matrix)\n",
    "    sim=cosine_similarity(tf_idf_matrix[0:1], tf_idf_matrix[1:2])\n",
    "    if(sim>max_similarity and idx!=src_index):\n",
    "        max_similarity=sim\n",
    "        max_similar_index=idx\n",
    "\n",
    "#display the results\n",
    "print('\\n\\n\\nThe document that is the most similar is presented below : \\n\\n\\n',twenty_train.data[max_similar_index])\n",
    "print('The similarity is : ',max_similarity[0][0])\n",
    "print('The category of this document is ',twenty_train.target_names[twenty_train.target[max_similar_index]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
